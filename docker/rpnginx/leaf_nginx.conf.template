server {
    listen ${HTTP_PORT} default_server;
    #listen [::]:${HTTP_PORT};
    server_name ${HOST};
    root /var/www/html;
    return 301 https://$server_name$request_uri;
}

upstream backend_api_servers{
  server leaf-nginx-1:8081;
  server leaf-nginx-api-1:8088 backup;
}

server {

    listen ${HTTPS_PORT} ssl http2 default_server;
    #listen [::]:${HTTPS_PORT} ssl http2 default_server;

    ssl_certificate /etc/ssl/certs/leaf.pem;
    ssl_certificate_key /etc/ssl/certs/leaf.key;
    ssl_protocols TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    client_max_body_size 20m;

    error_log  /var/log/nginx/error.log;
    access_log /var/log/nginx/access.log;

    #no ports in any redirect.
    port_in_redirect off;

    server_name ${HOST};
    root /var/www/html;
    index index.php index.html index.htm;


        location /health-check {
         access_log off;
          return 200 ok;
          add_header Content-Type text/plain;
        }
        
        # static files browser caching
        location ~* \.(jpg|jpeg|png|gif|ico|css|js)$ {
            #how long a browser should wait on checking for new cache, how far in advance do we want to go? Leaving at 15m for testing, MS talked about 12ish hours iirc
            expires 15m;
            #leave these out of the access log, who cares if someone access the leaf logo at 1245 pm
            access_log off;
            add_header Vary Accept-Encoding;
            #send the whole file, I think this wont have any effect with proxy pass.
            #tcp_nodelay off;
            #If many changes to the file it can cause the file not to load, waiting the 45s between file changes keeps it
            #from failing. This should not be too much of an issue on live and helps perf
            #open_file_cache max=3000 inactive=120s;
            #open_file_cache_valid 45s;
            #open_file_cache_min_uses 2;
            #open_file_cache_errors off;
            #the magic sauce to bust a cache
            etag on;
            proxy_pass http://${NGINX_POD}:8081;
        }
	
        location / { 
            
          proxy_pass http://${NGINX_POD}:8081;
          proxy_set_header Host host.docker.internal;
          proxy_redirect     off;
          proxy_set_header   X-Real-IP  $remote_addr;
          proxy_set_header   X-Scheme   $scheme;
          proxy_set_header   X-Forwarded-Proto https;
          proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
	  proxy_set_header   X-Proto on;
	  proxy_set_header   REFERER $http_referer; 
	  proxy_http_version 1.1; 
          proxy_connect_timeout 600;
          proxy_read_timeout 600;
	  proxy_buffer_size 16k;
          proxy_buffers 32 8k;
          proxy_busy_buffers_size 64k;
	  proxy_intercept_errors on;
          error_page 404 /404.html;
             location = /404.html {
                root /usr/share/nginx/html;
                internal;
          }
	  error_page 403 /403.html;
	     location = /403.html {
		root /usr/share/nginx/html;
		internal;
	  }

        }
        
       location ~ /api/(.*?)$ {
          proxy_pass http://backend_api_servers;
          
          #this is what is used to tell nginx that we want the next server
          proxy_next_upstream error timeout invalid_header http_500 http_502 http_504;
          proxy_next_upstream_tries 2;
          proxy_intercept_errors on;
          proxy_no_cache 1;
          proxy_cache_bypass 1;

          #proxy_set_header Host host.docker.internal;
          proxy_redirect     off;
          proxy_set_header   X-Real-IP  $remote_addr;
          proxy_set_header   X-Scheme   $scheme;
          proxy_set_header   X-Forwarded-Proto https;
          proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
          proxy_set_header   X-Proto on;
          proxy_set_header   REFERER $http_referer;
          proxy_http_version 1.1;
          proxy_connect_timeout 600;
          proxy_read_timeout 600;
          proxy_buffer_size 16k;
          proxy_buffers 32 8k;
          proxy_busy_buffers_size 64k;
       }



    #location /adminer {
    #    proxy_pass ${LEAF}:8080;
    #}
}
